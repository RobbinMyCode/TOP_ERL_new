# Global config
exp_name: &exp_name "hopper_seq_entire"
exp_path: &exp_path "../../mprl_exp_result"
sub_exp_name: &sub_exp_name "Hopper, final"
act_func_hidden: &act_func_hidden leaky_relu
act_func_last: &act_func_last null
dtype: &dtype "float32"
device: &device "cuda"
seed: auto

# cw2 config
name: *exp_name
path: *exp_path
verbose_level: 2

# wandb
wandb:
  project: *exp_name
  group: *sub_exp_name
  entity: YOU_USER_NAME
  log_interval: &log_interval 100
  log_model: true
  model_name: model

# experiment parameters
params:
  agent:
    type: TopErlAgentMultiProcessing
    # type: TopErlAgent
    args:
      lr_policy: 1e-4
      lr_critic: 1e-4
      wd_policy: 5e-5
      wd_critic: 5e-5
      use_mix_precision: true
      schedule_lr_policy: false
      schedule_lr_critic: false
      entropy_penalty_coef: 0.0
      discount_factor: 1
      epochs_policy: 10
      epochs_critic: 20
      balance_check: *log_interval
      evaluation_interval: *log_interval
      use_old_policy: true  # use a target policy as the old policy for the trust region projection
      old_policy_update_rate: 0.005  # update rate for the old policy from the current policy
      batch_size: 256
      critic_update_from: 1
      policy_update_from: 250
      dtype: *dtype
      device: *device

  mp: &mp
    type: prodmp
    args:
      num_dof: 3
      tau: 0.8
      alpha_phase: 3
      num_basis: 3
      basis_bandwidth_factor: 3
      num_basis_outside: 0
      alpha: 10
      dt: &dt 0.008
      auto_scale_basis: true
      relative_goal: false
      weights_scale: 1
      goal_scale: 1
      dtype: *dtype
      device: *device

  policy:
    type: TopErlPolicy
    args:
      mean_net_args:
        avg_neuron: 128
        num_hidden: 2
        shape: 0.0
      variance_net_args:
        std_only: false
        contextual: false
      init_method: orthogonal
      out_layer_gain: 0.01
      min_std: 1e-4
      act_func_hidden: *act_func_hidden
      act_func_last: *act_func_last
      dtype: *dtype
      device: *device
      mp: *mp

  critic:
    type: TopErlCritic
    args:
      bias: true
      n_embd: 128
      block_size: 1024
      dropout: 0.0
      n_layer: 2
      n_head: 8
      update_rate: 0.005
      use_layer_norm: true
      relative_pos: false # false for abs pos encoding, true for relative pos encoding
      single_q: true
      dtype: *dtype
      device: *device

  projection:
    type: KLProjectionLayer  # KL-projection
    args:
      proj_type: kl
      mean_bound: 0.1
      cov_bound: 0.02
      trust_region_coeff: 1.0
      scale_prec: true
      entropy_schedule: false  # Desired value is linear or exp or None
      target_entropy: 0.0 # target entropy per action dim
      temperature: 0.7
      entropy_eq: false # If the entropy should follow an equality constraint
      entropy_first: false # If the entropy should be the first constraint
      do_regression: false
      dtype: *dtype
      device: *device

  sampler:
    type: TopErlSampler
    args:
      env_id: "fancy_ProDMP_TCE/HopperJumpSparse-v0"
      dtype: *dtype
      device: *device
      seed: auto
      task_specified_metrics: ["max_height", "goal_dist", "height_rew", "healthy_reward"]

  replay_buffer:
    type: TopErlReplayBuffer
    args:
      buffer_size: 1000
      device: *device
      dtype: *dtype
