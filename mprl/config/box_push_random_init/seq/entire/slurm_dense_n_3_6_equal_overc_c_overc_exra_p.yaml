---
name: "SLURM"
partition: "accelerated"
job-name: "box_random_seq_entire_rand_fixed"
num_parallel_jobs: 120
ntasks: 1
cpus-per-task: 152
time: 2800 #600 for 10 hours
gpus_per_rep: 1
scheduler: horeka
sbatch_args:
  gres: "gpu:4"


experiment_copy_src:
  - "../" # RL Code base
experiment_copy_auto_dst: "../../CODE_COPY/"
---
name: box_random_seq_entire
import_path: "./shared_dense_n=3_6_equal_overc_c_overc_extra_p.yaml"
import_exp: "box_random_seq_entire"




# cw2 config
repetitions: 2      # Number of repetitions, each with different random seed, 2 [for hyper paremtertuning 2] or 4 for test, 20 for paper
reps_per_job: 4     # job id assigment
reps_in_parallel: 4 #jobs run in parallel = # of gpus used
iterations: &iterations 50000
num_checkpoints: 1

# Hardware specific parameters
params:
  sampler:
    args:
      num_env_train: 4
      num_env_test: 38
      episodes_per_train_env: 1
      episodes_per_test_env: 4
  projection:
    args:
      total_train_steps: *iterations

grid:
  reference_split:
    re_use_rand_coord_from_sampler_for_updates: [True, False]
    n_splits: [2, 3, 4, 5, 6]






