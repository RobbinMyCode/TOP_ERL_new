---
name: "SLURM"
partition: "accelerated"
job-name: "box_random_seq_entire_rand_fixed"
num_parallel_jobs: 120
ntasks: 1
cpus-per-task: 152
time: 2000 #600 for 10 hours
gpus_per_rep: 1
scheduler: horeka
sbatch_args:
  gres: "gpu:4"


experiment_copy_src:
  - "../" # RL Code base
experiment_copy_auto_dst: "../../CODE_COPY/"
---
name: box_random_seq_entire
import_path: "./shared_dense_n=2_equal_overc_c_overc_extra_p_lr_tune.yaml"
import_exp: "box_random_seq_entire"




# cw2 config
repetitions: 2      # Number of repetitions, each with different random seed, 2 [for hyper paremtertuning 2] or 4 for test, 20 for paper
reps_per_job: 4     # job id assigment
reps_in_parallel: 4 #jobs run in parallel = # of gpus used
iterations: &iterations 35000
num_checkpoints: 1

# Hardware specific parameters
params:
  sampler:
    args:
      num_env_train: 4
      num_env_test: 38
      episodes_per_train_env: 1
      episodes_per_test_env: 4
  projection:
    args:
      total_train_steps: *iterations

grid:
  agent:
    args:
      lr_policy: [1e-4, 2e-4,   3e-4,   4e-4, 5e-4, 6e-4]
      lr_critic: [1e-5, 3.5e-5, 5e-5, 6.5e-5, 8e-5, 1e-4]


