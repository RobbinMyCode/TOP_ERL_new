---
name: "SLURM"
partition: "accelerated"
job-name: "box_random_seq_entire"
num_parallel_jobs: 120
ntasks: 1
cpus-per-task: 152
time: 2000 #600 for 10 hours
gpus_per_rep: 1
scheduler: horeka
sbatch_args:
  gres: "gpu:4"

experiment_copy_src:
  - "../" # RL Code base
experiment_copy_auto_dst: "../../CODE_COPY/"
---
name: box_random_seq_entire
import_path: "./shared_dense_convergence_comparison.yaml"
import_exp: "box_random_seq_entire"

# cw2 config
repetitions: 2      # Number of repetitions, each with different random seed, 2 [for hyper paremtertuning 2] or 4 for test, 20 for paper
reps_per_job: 4     # job id assigment
reps_in_parallel: 4 #jobs run in parallel = # of gpus used
iterations: &iterations 35000
num_checkpoints: 1

# Hardware specific parameters
params:
  sampler:
    args:
      num_env_train: 4
      num_env_test: 38
      episodes_per_train_env: 1
      episodes_per_test_env: 4
  projection:
    args:
      total_train_steps: *iterations

list:
  agent:
    args:
      critic_update_from: [1,   1,    1,    1, 50, 50,    50,   50, 100, 100,  100,  100, 200, 200,  200,   200, 300, 300,  300,  300]
      policy_update_from: [1, 100, 1000, 2000, 50, 100, 1000, 2000, 100, 200, 1000, 2000, 200, 300,  1000, 2000, 300, 400, 1000, 2000]